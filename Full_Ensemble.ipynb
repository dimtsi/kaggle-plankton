{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math;\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import importlib\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from torchvision.models.resnet import *\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "\n",
    "import NNs\n",
    "from NNs import *\n",
    "importlib.reload(NNs)\n",
    "import math\n",
    "from NNs import ResNetDynamic, FeatureBoostedCNN\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from torchsummary import summary\n",
    "from Preprocessing import *\n",
    "from Preprocessing import ListsTrainDataset, ListsTestDataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/dimtsi/Dropbox/UvA/1st Semester/Applied Machine Learning/Project', '/home/dimtsi/anaconda3/envs/torch/lib/python37.zip', '/home/dimtsi/anaconda3/envs/torch/lib/python3.7', '/home/dimtsi/anaconda3/envs/torch/lib/python3.7/lib-dynload', '', '/home/dimtsi/.local/lib/python3.7/site-packages', '/home/dimtsi/anaconda3/envs/torch/lib/python3.7/site-packages', '/home/dimtsi/anaconda3/envs/torch/lib/python3.7/site-packages/IPython/extensions', '/home/dimtsi/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_images = pickle.load(open(\"pkl/train_padded64.pkl\", \"rb\"))\n",
    "# train_images = train_images[:1000]\n",
    "original_labels = pickle.load(open(\"pkl/train_labels.pkl\", \"rb\"))\n",
    "kaggle_test_images = pickle.load(open(\"pkl/test_padded64.pkl\", \"rb\"))\n",
    "kaggle_test_filenames = pickle.load(open(\"pkl/test_filenames.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load handcrafted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_haralick = pickle.load(open(\"features/train_haralick.pkl\", \"rb\"))\n",
    "original_moments = pickle.load(open(\"features/train_moments.pkl\", \"rb\"))\n",
    "original_sizes = pickle.load(open(\"features/train_sizes.pkl\", \"rb\"))\n",
    "\n",
    "kaggle_test_haralick = pickle.load(open(\"features/test_haralick.pkl\", \"rb\"))\n",
    "kaggle_test_moments = pickle.load(open(\"features/test_moments.pkl\", \"rb\"))\n",
    "kaggle_test_sizes = pickle.load(open(\"features/test_sizes.pkl\", \"rb\"))\n",
    "\n",
    "train_handcrafted_features = np.concatenate([original_haralick, original_moments,  original_sizes], axis =1)\n",
    "kaggle_test_handcrafted_features = np.concatenate([kaggle_test_haralick, kaggle_test_moments,  kaggle_test_sizes], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to train test mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_mine_indexes = pickle.load(open(\"pkl/test_set_mine_indexes.pkl\", \"rb\"))\n",
    "\n",
    "train_images = [i for j, i in enumerate(original_train_images) if j not in test_set_mine_indexes]\n",
    "train_labels = [i for j, i in enumerate(original_labels) if j not in test_set_mine_indexes]\n",
    "train_handcrafted = [i for j, i in enumerate(train_handcrafted_features) if j not in test_set_mine_indexes]\n",
    "\n",
    "#\n",
    "test_mine_images = [i for j, i in enumerate(original_train_images) if j in test_set_mine_indexes]\n",
    "test_mine_labels = [i for j, i in enumerate(original_labels) if j in test_set_mine_indexes]\n",
    "test_mine_handcrafted = [i for j, i in enumerate(train_handcrafted_features) if j in test_set_mine_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn, y_train_cnn = train_images, train_labels\n",
    "X_val_cnn, y_val_cnn = test_mine_images, test_mine_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = resnet50(pretrained = True)\n",
    "cnn = ResNetDynamic(pretrained.block, pretrained.layers, num_layers = 2, pretrained_nn = None)\n",
    "#\n",
    "cnn_dict = torch.load('models/all_elements_trained_model_90_new.pt', map_location={\"cuda:1\": \"cuda:0\", \"cuda:2\": \"cuda:0\"})['state_dict']\n",
    "cnn.load_state_dict(cnn_dict)\n",
    "cnn = cnn.eval().cuda()\n",
    "del(pretrained)\n",
    "feature_extractor_cnn = nn.Sequential(*list(cnn.children())[:-2]).eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_norm_test, std_norm_test = calc_means_stds(train_images)\n",
    "\n",
    "def get_cnn_features(feature_extractor, model, x):\n",
    "    features = ...\n",
    "    mean_norm_test, std_norm_test = calc_means_stds(train_images)\n",
    "\n",
    "    test_transforms = transforms. Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[mean_norm_test],\n",
    "                    std =[std_norm_test])\n",
    "    ])\n",
    "    \n",
    "    total_features = torch.Tensor().float().cpu()\n",
    "    total_predicted = torch.Tensor().long()\n",
    "    total_probabilities = torch.Tensor().float()  \n",
    "    \n",
    "    cnn_dataset = ListsTestDataset(x, transform = test_transforms)\n",
    "    cnn_loader = torch.utils.data.DataLoader(cnn_dataset, batch_size = 32, shuffle = False)\n",
    "\n",
    "    predictions = []\n",
    "    for i, images in enumerate(cnn_loader):\n",
    "        images = Variable(images, requires_grad=False).cuda()\n",
    "        outputs = model(images).cuda()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features = feature_extractor(images)\n",
    "        \n",
    "        total_features = torch.cat((total_features, features.detach().cpu()))\n",
    "        total_predicted = torch.cat((total_predicted, predicted.cpu().long()))\n",
    "        total_probabilities = torch.cat((total_probabilities,(torch.nn.Softmax()(outputs)).detach().cpu()))\n",
    "\n",
    "    return (total_features.numpy(), total_predicted.numpy(), total_probabilities.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimtsi/anaconda3/envs/torch/lib/python3.7/site-packages/ipykernel_launcher.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "cnn_train_features, cnn_train_predictions, cnn_train_probabilities = get_cnn_features(feature_extractor_cnn, cnn, X_train_cnn)\n",
    "cnn_val_features, cnn_val_predictions, cnn_val_probabilities = get_cnn_features(feature_extractor_cnn, cnn, X_val_cnn)\n",
    "cnn_kaggle_features, cnn_kaggle_predictions, cnn_kaggle_probabilities = get_cnn_features(feature_extractor_cnn, cnn, kaggle_test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and Preprocess for Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_handcrafted_train = scaler.fit_transform(train_handcrafted)\n",
    "scaled_handcrafted_val = scaler.fit_transform(test_mine_handcrafted)\n",
    "scaled_handcrafted_kaggle = scaler.fit_transform(kaggle_test_handcrafted_features)\n",
    "scaled_cnn_train_features = scaler.fit_transform(cnn_train_features)\n",
    "scaled_cnn_val_features = scaler.fit_transform(cnn_val_features)\n",
    "scaled_cnn_kaggle_features = scaler.fit_transform(cnn_kaggle_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Features DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = []\n",
    "\n",
    "for i in range(original_haralick.shape[1]):\n",
    "    feature_names.append(\"haralick\"+str(i))\n",
    "for i in range(original_moments.shape[1]):\n",
    "    feature_names.append(\"moments\"+str(i))\n",
    "for i in range(original_sizes.shape[1]):\n",
    "    feature_names.append(\"sizes\"+str(i))\n",
    "for i in range(scaled_cnn_train_features.shape[1]):\n",
    "    feature_names.append(\"deep\"+str(i))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##concat handcrafted and deep features\n",
    "\n",
    "NP_FEATURES_TRAIN = np.concatenate([scaled_handcrafted_train, scaled_cnn_train_features], axis = 1)\n",
    "NP_FEATURES_VAL = np.concatenate([scaled_handcrafted_val, scaled_cnn_val_features], axis = 1)\n",
    "NP_FEATURES_KAGGLE = np.concatenate([scaled_handcrafted_kaggle, scaled_cnn_kaggle_features], axis = 1)\n",
    "\n",
    "y_train = train_labels\n",
    "y_test = test_mine_labels\n",
    "\n",
    "X_train = pd.DataFrame(NP_FEATURES_TRAIN, columns = feature_names)\n",
    "X_test = pd.DataFrame(NP_FEATURES_VAL, columns = feature_names)\n",
    "X_kaggle = pd.DataFrame(NP_FEATURES_KAGGLE, columns = feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=40)\n",
    "\n",
    "concatenated = np.concatenate([X_train, X_test], axis =0)\n",
    "concatenated = np.concatenate([concatenated, X_kaggle], axis =0)\n",
    "\n",
    "principalComponents = pca.fit_transform(concatenated)\n",
    "principalComponents.shape\n",
    "\n",
    "x_train = principalComponents[:len(X_train)]\n",
    "x_test = principalComponents[len(X_train):len(X_train)+len(X_test)]\n",
    "x_kaggle = principalComponents[len(X_train)+len(X_test):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Base Learners\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = x_train.shape[0]\n",
    "ntest = x_test.shape[0]\n",
    "nkaggle = x_kaggle.shape[0]\n",
    "\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "\n",
    "kf = KFold(n_splits = NFOLDS, random_state=SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model, train_data, test_data, training_labels, test_labels):\n",
    "    y_pred_train = model.predict(train_data)\n",
    "    y_pred_test = model.predict(test_data)\n",
    "    print(\"Training Accuracy: \" +str(accuracy_score(training_labels, y_pred_train)))\n",
    "    print(\"Validation Accuracy: \" +str(accuracy_score(test_labels, y_pred_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Weak Classifiers Params\n",
    "\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 0.2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.2\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.5585106382978723\n",
      "elapsed time: 4.678390026092529\n"
     ]
    }
   ],
   "source": [
    "##DTree\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "dt_model.fit(x_train, y_train)\n",
    "get_results(dt_model, x_train, x_test, y_train, y_test)\n",
    "\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"elapsed time: \"+str(elapsed_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5304481387784604\n",
      "Validation Accuracy: 0.4990328820116054\n",
      "elapsed time: 27.98748779296875\n"
     ]
    }
   ],
   "source": [
    "##RandomForest\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "rf_model.fit(x_train, y_train)\n",
    "get_results(rf_model, x_train, x_test, y_train, y_test)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"elapsed time: \"+str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8628026743765811\n",
      "Validation Accuracy: 0.6914893617021277\n",
      "elapsed time: 347.52951526641846\n"
     ]
    }
   ],
   "source": [
    "##XGBoost\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "xgb_model = XGBClassifier(nthread=-1, learning_rate = 0.01, min_child_weight = 0.01, max_depth=5, param)\n",
    "xgb_model.fit(x_train, y_train)\n",
    "get_results(xgb_model, x_train, x_test, y_train, y_test)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"elapsed time: \"+str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AdaBoostClassifier' object has no attribute '__name__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-ddcdc138c86b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mada_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mada_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mada_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-92d02af49105>\u001b[0m in \u001b[0;36mget_results\u001b[0;34m(model, train_data, test_data, training_labels, test_labels)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Accuracy: \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Accuracy: \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AdaBoostClassifier' object has no attribute '__name__'"
     ]
    }
   ],
   "source": [
    "##AdaBoost\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "ada_model = AdaBoostClassifier(**ada_params)\n",
    "ada_model.fit(x_train, y_train)\n",
    "get_results(ada_model, x_train, x_test, y_train, y_test)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"elapsed time: \"+str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.668548970003614\n",
      "Validation Accuracy: 0.620889748549323\n",
      "elapsed time: 11.891568899154663\n"
     ]
    }
   ],
   "source": [
    "##ExtraTrees\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "et_model = ExtraTreesClassifier(**et_params)\n",
    "et_model.fit(x_train, y_train)\n",
    "get_results(et_model, x_train, x_test, y_train, y_test)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"elapsed time: \"+str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8057914709071197\n",
      "Validation Accuracy: 0.7296905222437138\n",
      "elapsed time: 80.74974918365479\n"
     ]
    }
   ],
   "source": [
    "##SVM\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "svm = SVC(**svc_params)\n",
    "svm.fit(scaler.fit_transform(x_train), y_train)\n",
    "get_results(svm, scaler.fit_transform(x_train), scaler.fit_transform(x_test), y_train, y_test)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"elapsed time: \"+str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-da5a20144ea0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0meclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'knn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'svc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'soft'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clf1' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "eclf = VotingClassifier(estimators=[('dt', dt_model), ('rf', rf_model) ('et', clf2), ('xgb', xgb_model), ('ada', ada_model), ('svm = svm_model')], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_results = svm.predict(scaler.fit_transform(x_kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_results = pd.read_csv('best_results.csv')\n",
    "\n",
    "# best_results['predicted']=svm_results\n",
    "\n",
    "# best_results = best_results.drop(columns=['class'])\n",
    "\n",
    "# final = best_results.rename(index=str, columns={\"predicted\": \"class\"})\n",
    "# final\n",
    "# final.to_csv('results.csv',sep = ',', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
