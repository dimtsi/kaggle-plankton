{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import math;\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pickle.load(open(\"pkl/preprocessed_train_images.pkl\", \"rb\"))\n",
    "train_labels = pickle.load(open(\"pkl/train_labels.pkl\", \"rb\"))\n",
    "train_filenames = pickle.load(open(\"pkl/train_filenames.pkl\", \"rb\"))\n",
    "test_images = pickle.load(open(\"pkl/preprocessed_test_images.pkl\", \"rb\"))\n",
    "test_filenames = pickle.load(open(\"pkl/test_filenames.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average width 64.0 , Average height: 64.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PIL\n",
    "\n",
    "widths, heights = [], [] \n",
    "sumx, sumy = 0, 0\n",
    "for i in train_images:\n",
    "    sumx += i.size[0]\n",
    "    widths.append(i.size[0])\n",
    "    sumy += i.size[1]\n",
    "    heights.append(i.size[1])\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.hist(widths)\n",
    "ax2.hist(heights, color = 'orange')\n",
    "fig.set_size_inches(12, 5)\n",
    "\n",
    "avg_width = np.mean(widths)\n",
    "avg_height = np.mean(heights)\n",
    "print('Average width {} , Average height: {}'.format(avg_width, avg_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListsTrainDataset(Dataset):\n",
    "    def __init__(self, list_of_images, list_of_labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            height (int): image height\n",
    "            width (int): image width\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "#         super().__init__()\n",
    "        self.data = list_of_images\n",
    "        self.labels = np.asarray(list_of_labels).reshape(-1,1)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_image = self.data[index]\n",
    "        single_image_label = self.labels[index]\n",
    "        # Transform image to tensor\n",
    "        if self.transform is not None:\n",
    "            img_as_tensor = self.transform(single_image)\n",
    "        # Return image and the label\n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListsTestDataset(Dataset):\n",
    "    def __init__(self, list_of_images, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            height (int): image height\n",
    "            width (int): image width\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        self.data = list_of_images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_image = self.data[index]\n",
    "        if self.transform is not None:\n",
    "            img_as_tensor = self.transform(single_image)\n",
    "        # Return image ONLY\n",
    "        return img_as_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms and Dataset Creation\n",
    "def create_datasets_dataloaders(X_train, y_train, X_test= None, y_test = None):\n",
    "    test_transforms = transforms. Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    train_transforms = transforms. Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=360),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    train_dataset = ListsTrainDataset(X_train, y_train, transform = train_transforms)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle = True, num_workers=0)\n",
    "\n",
    "    if y_test is not None:\n",
    "        test_dataset = ListsTrainDataset(X_test, y_test, transform = test_transforms)\n",
    "    else:\n",
    "        test_dataset = ListsTestDataset(X_test, transform = test_transforms)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle = False)\n",
    "    return (train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import BasicBlock, Bottleneck, ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, num_epochs):\n",
    "    learning_rate = 0.0005\n",
    "    batch_size = data_loader.batch_size\n",
    "    criterion = nn.CrossEntropyLoss();\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate);\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate);\n",
    "    #Training\n",
    "    history = {'batch': [], 'loss': [], 'accuracy': []}\n",
    "    for epoch in range(num_epochs):\n",
    "            for i, (images, labels) in enumerate(data_loader):\n",
    "                images = Variable(images).cuda()\n",
    "                labels = Variable(labels).squeeze(1).long().cuda()#.cpu()\n",
    "                # Forward + Backward + Optimize\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                _, argmax = torch.max(outputs, 1)\n",
    "                accuracy_train = (labels == argmax.squeeze()).float().mean()*100\n",
    "                # Show progress\n",
    "                if (i+1) % 32 == 0:\n",
    "                    log = \" \".join([\n",
    "                      \"Epoch : %d/%d\" % (epoch+1, num_epochs),\n",
    "                      \"Iter : %d/%d\" % (i+1, len(data_loader.dataset)//batch_size),\n",
    "                      \"Loss: %.4f\" % loss.item(),\n",
    "                      \"Accuracy: %.4f\" % accuracy_train])\n",
    "                    print('\\r{}'.format(log), end='')\n",
    "                    history['batch'].append(i)\n",
    "                    history['loss'].append(loss.item())\n",
    "                    history['accuracy'].append(accuracy_train.item())\n",
    "            print()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cnn.eval().cuda()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# for images, labels in test_loader:\n",
    "#     images = Variable(images)\n",
    "#     labels= labels.squeeze(1)\n",
    "#     outputs = cnn(images)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     total += labels.size(0)\n",
    "#     correct += (predicted.float() == labels).sum()\n",
    "# print('Test Accuracy of the model on the 60000 test images: %.4f %%' % (100*correct.item() / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def predict_test_set(model, loader, filenames):\n",
    "    predictions = []\n",
    "    for images in loader:\n",
    "        images = Variable(images).cuda()\n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        predictions.extend(prediction.cpu().numpy())\n",
    "    results_df = pd.DataFrame({'image': test_filenames, 'class': predictions}, columns=['image', 'class'])\n",
    "    results_df.to_csv('results.csv',sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_loader, test_loader = create_datasets_dataloaders(train_images, train_labels)\n",
    "# cnn = ResNetMine(Bottleneck, [1, 1, 1, 1]).cuda()\n",
    "# trained_model = train(cnn, train_loader, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##predict on testset\n",
    "\n",
    "# test_transforms = transforms. Compose([\n",
    "#         transforms.CenterCrop(64),\n",
    "#         transforms.ToTensor()\n",
    "#     ])\n",
    "\n",
    "# test_dataset = ListsTestDataset(test_images, transform = test_transforms)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = False)\n",
    "\n",
    "# predict_test_set(trained_model, test_loader, test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, test_loader, num_epochs):\n",
    "    learning_rate = 0.0001\n",
    "    weight_decay = 0.00005\n",
    "    batch_size = train_loader.batch_size\n",
    "    criterion = nn.CrossEntropyLoss();\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay = weight_decay);\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate);\n",
    "    #Training\n",
    "    history = {'batch': [], 'loss': [], 'accuracy': []}\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train().cuda()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = Variable(images).cuda()\n",
    "            labels = Variable(labels).squeeze(1).long().cuda()#.cpu()\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, argmax = torch.max(outputs, 1)\n",
    "            accuracy_train = (labels == argmax.squeeze()).float().mean()*100\n",
    "            # Show progress\n",
    "            if (i+1) % 32 == 0:\n",
    "                log = \" \".join([\n",
    "                  \"Epoch : %d/%d\" % (epoch+1, num_epochs),\n",
    "                  \"Iter : %d/%d\" % (i+1, len(train_loader.dataset)//batch_size),\n",
    "                  \"Loss: %.4f\" % loss.item(),\n",
    "                  \"Accuracy: %.4f\" % accuracy_train])\n",
    "                print('\\r{}'.format(log), end='')\n",
    "                history['batch'].append(i)\n",
    "                history['loss'].append(loss.item())\n",
    "                history['accuracy'].append(accuracy_train.item())\n",
    "        print()\n",
    "        ##VALIDATION SCORE AFTER EVERY EPOCH\n",
    "        model.eval().cuda()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = Variable(images).cuda()\n",
    "            labels= labels.squeeze(1)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.cpu().long() == labels).sum()\n",
    "        print('VALIDATION SET ACCURACY: %.4f %%' % (100*correct.item() / total))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import NNs\n",
    "import math\n",
    "importlib.reload(NNs)\n",
    "from NNs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 34, 34]             576\n",
      "       BatchNorm2d-2           [-1, 64, 34, 34]             128\n",
      "              ReLU-3           [-1, 64, 34, 34]               0\n",
      "         MaxPool2d-4           [-1, 64, 17, 17]               0\n",
      "            Conv2d-5           [-1, 64, 17, 17]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 17, 17]             128\n",
      "              ReLU-7           [-1, 64, 17, 17]               0\n",
      "            Conv2d-8           [-1, 64, 17, 17]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 17, 17]             128\n",
      "             ReLU-10           [-1, 64, 17, 17]               0\n",
      "           Conv2d-11          [-1, 256, 17, 17]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 17, 17]             512\n",
      "           Conv2d-13          [-1, 256, 17, 17]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 17, 17]             512\n",
      "             ReLU-15          [-1, 256, 17, 17]               0\n",
      "       Bottleneck-16          [-1, 256, 17, 17]               0\n",
      "           Conv2d-17          [-1, 128, 17, 17]          32,768\n",
      "      BatchNorm2d-18          [-1, 128, 17, 17]             256\n",
      "             ReLU-19          [-1, 128, 17, 17]               0\n",
      "           Conv2d-20            [-1, 128, 9, 9]         147,456\n",
      "      BatchNorm2d-21            [-1, 128, 9, 9]             256\n",
      "             ReLU-22            [-1, 128, 9, 9]               0\n",
      "           Conv2d-23            [-1, 512, 9, 9]          65,536\n",
      "      BatchNorm2d-24            [-1, 512, 9, 9]           1,024\n",
      "           Conv2d-25            [-1, 512, 9, 9]         131,072\n",
      "      BatchNorm2d-26            [-1, 512, 9, 9]           1,024\n",
      "             ReLU-27            [-1, 512, 9, 9]               0\n",
      "       Bottleneck-28            [-1, 512, 9, 9]               0\n",
      "        AvgPool2d-29            [-1, 512, 4, 4]               0\n",
      "           Linear-30                  [-1, 121]         991,353\n",
      "================================================================\n",
      "Total params: 1,446,457\n",
      "Trainable params: 1,446,457\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 9.11\n",
      "Params size (MB): 5.52\n",
      "Estimated Total Size (MB): 14.65\n",
      "----------------------------------------------------------------\n",
      "Epoch : 1/150 Iter : 672/680 Loss: 2.8841 Accuracy: 18.7500\n",
      "VALIDATION SET ACCURACY: 32.7551 %\n",
      "Epoch : 2/150 Iter : 672/680 Loss: 2.5387 Accuracy: 28.1250\n",
      "VALIDATION SET ACCURACY: 30.5246 %\n",
      "Epoch : 3/150 Iter : 672/680 Loss: 2.4753 Accuracy: 34.3750\n",
      "VALIDATION SET ACCURACY: 39.8596 %\n",
      "Epoch : 4/150 Iter : 672/680 Loss: 2.8163 Accuracy: 37.5000\n",
      "VALIDATION SET ACCURACY: 43.3292 %\n",
      "Epoch : 5/150 Iter : 672/680 Loss: 1.7473 Accuracy: 50.0000\n",
      "VALIDATION SET ACCURACY: 36.7617 %\n",
      "Epoch : 6/150 Iter : 672/680 Loss: 1.6907 Accuracy: 53.1250\n",
      "VALIDATION SET ACCURACY: 46.9641 %\n",
      "Epoch : 7/150 Iter : 672/680 Loss: 1.5706 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 47.9554 %\n",
      "Epoch : 8/150 Iter : 672/680 Loss: 1.7304 Accuracy: 40.6250\n",
      "VALIDATION SET ACCURACY: 47.9141 %\n",
      "Epoch : 9/150 Iter : 672/680 Loss: 1.3410 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 48.0793 %\n",
      "Epoch : 10/150 Iter : 672/680 Loss: 1.5757 Accuracy: 46.8750\n",
      "VALIDATION SET ACCURACY: 51.5076 %\n",
      "Epoch : 11/150 Iter : 672/680 Loss: 1.6010 Accuracy: 50.0000\n",
      "VALIDATION SET ACCURACY: 48.5750 %\n",
      "Epoch : 12/150 Iter : 672/680 Loss: 1.7318 Accuracy: 50.0000\n",
      "VALIDATION SET ACCURACY: 51.4250 %\n",
      "Epoch : 13/150 Iter : 672/680 Loss: 1.4046 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 53.8207 %\n",
      "Epoch : 14/150 Iter : 672/680 Loss: 1.5175 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 52.7881 %\n",
      "Epoch : 15/150 Iter : 672/680 Loss: 1.1548 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 53.6555 %\n",
      "Epoch : 16/150 Iter : 672/680 Loss: 1.1811 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 51.1772 %\n",
      "Epoch : 17/150 Iter : 672/680 Loss: 0.8685 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 56.0925 %\n",
      "Epoch : 18/150 Iter : 672/680 Loss: 1.6972 Accuracy: 46.8750\n",
      "VALIDATION SET ACCURACY: 57.3730 %\n",
      "Epoch : 19/150 Iter : 672/680 Loss: 1.7534 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 55.2251 %\n",
      "Epoch : 20/150 Iter : 672/680 Loss: 1.3743 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 53.8207 %\n",
      "Epoch : 21/150 Iter : 672/680 Loss: 0.6645 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 54.3164 %\n",
      "Epoch : 22/150 Iter : 672/680 Loss: 1.4761 Accuracy: 50.0000\n",
      "VALIDATION SET ACCURACY: 47.1706 %\n",
      "Epoch : 23/150 Iter : 672/680 Loss: 1.4779 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 51.5489 %\n",
      "Epoch : 24/150 Iter : 672/680 Loss: 1.2824 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 57.2078 %\n",
      "Epoch : 25/150 Iter : 672/680 Loss: 0.8213 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 57.4143 %\n",
      "Epoch : 26/150 Iter : 672/680 Loss: 1.2549 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 58.4469 %\n",
      "Epoch : 27/150 Iter : 672/680 Loss: 1.6225 Accuracy: 43.7500\n",
      "VALIDATION SET ACCURACY: 58.3230 %\n",
      "Epoch : 28/150 Iter : 672/680 Loss: 1.3387 Accuracy: 53.1250\n",
      "VALIDATION SET ACCURACY: 58.3230 %\n",
      "Epoch : 29/150 Iter : 672/680 Loss: 1.0743 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 58.1165 %\n",
      "Epoch : 30/150 Iter : 672/680 Loss: 0.8398 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 59.5622 %\n",
      "Epoch : 31/150 Iter : 672/680 Loss: 1.0545 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 57.5795 %\n",
      "Epoch : 32/150 Iter : 672/680 Loss: 0.7170 Accuracy: 84.3750\n",
      "VALIDATION SET ACCURACY: 60.8839 %\n",
      "Epoch : 33/150 Iter : 672/680 Loss: 1.3587 Accuracy: 53.1250\n",
      "VALIDATION SET ACCURACY: 56.9599 %\n",
      "Epoch : 34/150 Iter : 672/680 Loss: 1.5454 Accuracy: 43.7500\n",
      "VALIDATION SET ACCURACY: 56.0925 %\n",
      "Epoch : 35/150 Iter : 672/680 Loss: 1.2238 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 55.5143 %\n",
      "Epoch : 36/150 Iter : 672/680 Loss: 1.3790 Accuracy: 43.7500\n",
      "VALIDATION SET ACCURACY: 60.7187 %\n",
      "Epoch : 37/150 Iter : 672/680 Loss: 1.0355 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 60.2644 %\n",
      "Epoch : 38/150 Iter : 672/680 Loss: 1.3593 Accuracy: 50.0000\n",
      "VALIDATION SET ACCURACY: 59.3969 %\n",
      "Epoch : 39/150 Iter : 672/680 Loss: 0.8875 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 60.2644 %\n",
      "Epoch : 40/150 Iter : 672/680 Loss: 1.0507 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 59.4796 %\n",
      "Epoch : 41/150 Iter : 672/680 Loss: 1.1101 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 59.5209 %\n",
      "Epoch : 42/150 Iter : 672/680 Loss: 1.1842 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 60.0165 %\n",
      "Epoch : 43/150 Iter : 672/680 Loss: 0.7096 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 56.9186 %\n",
      "Epoch : 44/150 Iter : 672/680 Loss: 1.0157 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 62.0818 %\n",
      "Epoch : 45/150 Iter : 672/680 Loss: 0.9541 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 59.8513 %\n",
      "Epoch : 46/150 Iter : 672/680 Loss: 0.7946 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 56.2164 %\n",
      "Epoch : 47/150 Iter : 672/680 Loss: 0.7322 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 57.6621 %\n",
      "Epoch : 48/150 Iter : 672/680 Loss: 1.0519 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 63.2383 %\n",
      "Epoch : 49/150 Iter : 672/680 Loss: 0.7364 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 61.4209 %\n",
      "Epoch : 50/150 Iter : 672/680 Loss: 1.4534 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 62.0818 %\n",
      "Epoch : 51/150 Iter : 672/680 Loss: 0.8430 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 57.0838 %\n",
      "Epoch : 52/150 Iter : 672/680 Loss: 1.2585 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 64.1057 %\n",
      "Epoch : 53/150 Iter : 672/680 Loss: 0.7742 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 57.7034 %\n",
      "Epoch : 54/150 Iter : 672/680 Loss: 1.2906 Accuracy: 53.1250\n",
      "VALIDATION SET ACCURACY: 55.2251 %\n",
      "Epoch : 55/150 Iter : 672/680 Loss: 1.1187 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 62.6188 %\n",
      "Epoch : 56/150 Iter : 672/680 Loss: 1.1506 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 61.9579 %\n",
      "Epoch : 57/150 Iter : 672/680 Loss: 0.8856 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 63.3622 %\n",
      "Epoch : 58/150 Iter : 672/680 Loss: 1.0876 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 63.5275 %\n",
      "Epoch : 59/150 Iter : 672/680 Loss: 0.9012 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 57.5382 %\n",
      "Epoch : 60/150 Iter : 672/680 Loss: 0.7380 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 62.9492 %\n",
      "Epoch : 61/150 Iter : 672/680 Loss: 1.0230 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 59.9339 %\n",
      "Epoch : 62/150 Iter : 672/680 Loss: 1.4086 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 61.2970 %\n",
      "Epoch : 63/150 Iter : 672/680 Loss: 1.0096 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 64.7253 %\n",
      "Epoch : 64/150 Iter : 672/680 Loss: 0.7320 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 61.9166 %\n",
      "Epoch : 65/150 Iter : 672/680 Loss: 1.1634 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 64.3949 %\n",
      "Epoch : 66/150 Iter : 672/680 Loss: 1.0822 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 62.1231 %\n",
      "Epoch : 67/150 Iter : 672/680 Loss: 0.9317 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 62.5774 %\n",
      "Epoch : 68/150 Iter : 672/680 Loss: 1.0317 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 63.5275 %\n",
      "Epoch : 69/150 Iter : 672/680 Loss: 0.7431 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 64.5188 %\n",
      "Epoch : 70/150 Iter : 672/680 Loss: 1.5129 Accuracy: 53.1250\n",
      "VALIDATION SET ACCURACY: 62.7014 %\n",
      "Epoch : 71/150 Iter : 672/680 Loss: 0.9083 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 64.7253 %\n",
      "Epoch : 72/150 Iter : 672/680 Loss: 0.9739 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 54.6055 %\n",
      "Epoch : 73/150 Iter : 672/680 Loss: 0.6674 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 63.8992 %\n",
      "Epoch : 74/150 Iter : 672/680 Loss: 1.1048 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 64.7666 %\n",
      "Epoch : 75/150 Iter : 672/680 Loss: 0.6904 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 63.3209 %\n",
      "Epoch : 76/150 Iter : 672/680 Loss: 1.2671 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 64.9318 %\n",
      "Epoch : 77/150 Iter : 672/680 Loss: 1.0116 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 61.8753 %\n",
      "Epoch : 78/150 Iter : 672/680 Loss: 1.4139 Accuracy: 53.1250\n",
      "VALIDATION SET ACCURACY: 55.2664 %\n",
      "Epoch : 79/150 Iter : 672/680 Loss: 0.8340 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 63.5275 %\n",
      "Epoch : 80/150 Iter : 672/680 Loss: 0.6901 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 60.6774 %\n",
      "Epoch : 81/150 Iter : 672/680 Loss: 0.5989 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 65.7993 %\n",
      "Epoch : 82/150 Iter : 672/680 Loss: 0.7900 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 63.6514 %\n",
      "Epoch : 83/150 Iter : 672/680 Loss: 0.8589 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 54.6881 %\n",
      "Epoch : 84/150 Iter : 672/680 Loss: 0.8033 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 64.1057 %\n",
      "Epoch : 85/150 Iter : 672/680 Loss: 0.7552 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 63.8579 %\n",
      "Epoch : 86/150 Iter : 672/680 Loss: 0.5119 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 60.3883 %\n",
      "Epoch : 87/150 Iter : 672/680 Loss: 1.0626 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 58.7774 %\n",
      "Epoch : 88/150 Iter : 672/680 Loss: 0.6687 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 64.2297 %\n",
      "Epoch : 89/150 Iter : 672/680 Loss: 0.8567 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 63.8579 %\n",
      "Epoch : 90/150 Iter : 672/680 Loss: 0.7358 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 65.0558 %\n",
      "Epoch : 91/150 Iter : 672/680 Loss: 0.8397 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 64.0644 %\n",
      "Epoch : 92/150 Iter : 672/680 Loss: 0.9959 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 53.7381 %\n",
      "Epoch : 93/150 Iter : 672/680 Loss: 1.1890 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 65.7166 %\n",
      "Epoch : 94/150 Iter : 672/680 Loss: 0.6791 Accuracy: 84.3750\n",
      "VALIDATION SET ACCURACY: 66.0058 %\n",
      "Epoch : 95/150 Iter : 672/680 Loss: 0.5672 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 63.5275 %\n",
      "Epoch : 96/150 Iter : 672/680 Loss: 0.8179 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 65.1384 %\n",
      "Epoch : 97/150 Iter : 672/680 Loss: 0.7016 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 63.8579 %\n",
      "Epoch : 98/150 Iter : 672/680 Loss: 1.0024 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 63.7753 %\n",
      "Epoch : 99/150 Iter : 672/680 Loss: 0.6445 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 62.9492 %\n",
      "Epoch : 100/150 Iter : 672/680 Loss: 1.1350 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 63.8166 %\n",
      "Epoch : 101/150 Iter : 672/680 Loss: 0.4459 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 65.7580 %\n",
      "Epoch : 102/150 Iter : 672/680 Loss: 1.2598 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 65.1797 %\n",
      "Epoch : 103/150 Iter : 672/680 Loss: 0.4803 Accuracy: 87.5000\n",
      "VALIDATION SET ACCURACY: 59.8926 %\n",
      "Epoch : 104/150 Iter : 672/680 Loss: 0.8918 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 62.9492 %\n",
      "Epoch : 105/150 Iter : 672/680 Loss: 0.7094 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 64.4362 %\n",
      "Epoch : 106/150 Iter : 672/680 Loss: 1.2005 Accuracy: 53.1250\n",
      "VALIDATION SET ACCURACY: 60.3057 %\n",
      "Epoch : 107/150 Iter : 672/680 Loss: 0.8634 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 65.9645 %\n",
      "Epoch : 108/150 Iter : 672/680 Loss: 0.6516 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 66.6254 %\n",
      "Epoch : 109/150 Iter : 672/680 Loss: 0.8256 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 65.2623 %\n",
      "Epoch : 110/150 Iter : 672/680 Loss: 1.0629 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 61.4622 %\n",
      "Epoch : 111/150 Iter : 672/680 Loss: 0.6177 Accuracy: 87.5000\n",
      "VALIDATION SET ACCURACY: 59.8513 %\n",
      "Epoch : 112/150 Iter : 672/680 Loss: 0.6173 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 66.1710 %\n",
      "Epoch : 113/150 Iter : 672/680 Loss: 0.7189 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 59.8513 %\n",
      "Epoch : 114/150 Iter : 160/680 Loss: 0.8150 Accuracy: 65.6250"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=True)\n",
    "trained_models = []\n",
    "for train_indexes, validation_indexes in kf.split(train_images):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    \n",
    "    for i in train_indexes:\n",
    "        X_train.append(train_images[i])\n",
    "        y_train.append(train_labels[i])\n",
    "    for j in validation_indexes:\n",
    "        X_val.append(train_images[j])\n",
    "        y_val.append(train_labels[j])\n",
    "    train_loader, test_loader = create_datasets_dataloaders(\n",
    "        X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    #Training\n",
    "    cnn = ResNetMine(Bottleneck, [1,1]).cuda()\n",
    "#     cnn = CNN().cuda()\n",
    "    summary(cnn, (1,64,64))\n",
    "\n",
    "#     print(summary(cnn, (1,28,28)))\n",
    "    trained_model = train_and_validate(cnn, train_loader, test_loader, num_epochs=150)\n",
    "    trained_models.append(trained_model)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = trained_models[0].eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on testset\n",
    "def predict_test_set(model, loader, filenames):\n",
    "    predictions = []\n",
    "    for images in loader:\n",
    "        images = Variable(images).cuda()\n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        predictions.extend(prediction.cpu().numpy())\n",
    "    results_df = pd.DataFrame({'image': test_filenames, 'class': predictions}, columns=['image', 'class'])\n",
    "    results_df.to_csv('results.csv',sep = ',', index = False)\n",
    "\n",
    "\n",
    "test_transforms = transforms. Compose([\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "test_dataset = ListsTestDataset(test_images, transform = test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = False)\n",
    "\n",
    "predict_test_set(final_model, test_loader, test_filenames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "torch_92"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
