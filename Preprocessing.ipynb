{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import math;\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pickle.load(open(\"pkl/train_images.pkl\", \"rb\"))\n",
    "train_labels = pickle.load(open(\"pkl/train_labels.pkl\", \"rb\"))\n",
    "train_filenames = pickle.load(open(\"pkl/train_filenames.pkl\", \"rb\"))\n",
    "test_images = pickle.load(open(\"pkl/test_images.pkl\", \"rb\"))\n",
    "test_filenames = pickle.load(open(\"pkl/test_filenames.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average width 73.32110394976037 , Average height: 66.46897207073211\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PIL\n",
    "\n",
    "widths, heights = [], [] \n",
    "sumx, sumy = 0, 0\n",
    "for i in train_images:\n",
    "    sumx += i.size[0]\n",
    "    widths.append(i.size[0])\n",
    "    sumy += i.size[1]\n",
    "    heights.append(i.size[1])\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.hist(widths)\n",
    "ax2.hist(heights, color = 'orange')\n",
    "fig.set_size_inches(12, 5)\n",
    "\n",
    "avg_width = np.mean(widths)\n",
    "avg_height = np.mean(heights)\n",
    "print('Average width {} , Average height: {}'.format(avg_width, avg_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListsTrainDataset(Dataset):\n",
    "    def __init__(self, list_of_images, list_of_labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            height (int): image height\n",
    "            width (int): image width\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "#         super().__init__()\n",
    "        self.data = list_of_images\n",
    "        self.labels = np.asarray(list_of_labels).reshape(-1,1)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_image = self.data[index]\n",
    "        single_image_label = self.labels[index]\n",
    "        # Transform image to tensor\n",
    "        if self.transform is not None:\n",
    "            img_as_tensor = self.transform(single_image)\n",
    "        # Return image and the label\n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListsTestDataset(Dataset):\n",
    "    def __init__(self, list_of_images, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            height (int): image height\n",
    "            width (int): image width\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        self.data = list_of_images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_image = self.data[index]\n",
    "        if self.transform is not None:\n",
    "            img_as_tensor = self.transform(single_image)\n",
    "        # Return image ONLY\n",
    "        return img_as_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms and Dataset Creation\n",
    "def create_datasets_dataloaders(X_train, y_train, X_test= None, y_test = None):\n",
    "    test_transforms = transforms. Compose([\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    train_transforms = transforms. Compose([\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=360),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    train_dataset = ListsTrainDataset(X_train, y_train, transform = train_transforms)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle = True, num_workers=0)\n",
    "\n",
    "    if y_test is not None:\n",
    "        test_dataset = ListsTrainDataset(X_test, y_test, transform = test_transforms)\n",
    "    else:\n",
    "        test_dataset = ListsTestDataset(X_test, transform = test_transforms)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle = False)\n",
    "    return (train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import BasicBlock, Bottleneck, ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, num_epochs):\n",
    "    learning_rate = 0.0005\n",
    "    batch_size = data_loader.batch_size\n",
    "    criterion = nn.CrossEntropyLoss();\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate);\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate);\n",
    "    #Training\n",
    "    history = {'batch': [], 'loss': [], 'accuracy': []}\n",
    "    for epoch in range(num_epochs):\n",
    "            for i, (images, labels) in enumerate(data_loader):\n",
    "                images = Variable(images).cuda()\n",
    "                labels = Variable(labels).squeeze(1).long().cuda()#.cpu()\n",
    "                # Forward + Backward + Optimize\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                _, argmax = torch.max(outputs, 1)\n",
    "                accuracy_train = (labels == argmax.squeeze()).float().mean()*100\n",
    "                # Show progress\n",
    "                if (i+1) % 32 == 0:\n",
    "                    log = \" \".join([\n",
    "                      \"Epoch : %d/%d\" % (epoch+1, num_epochs),\n",
    "                      \"Iter : %d/%d\" % (i+1, len(data_loader.dataset)//batch_size),\n",
    "                      \"Loss: %.4f\" % loss.item(),\n",
    "                      \"Accuracy: %.4f\" % accuracy_train])\n",
    "                    print('\\r{}'.format(log), end='')\n",
    "                    history['batch'].append(i)\n",
    "                    history['loss'].append(loss.item())\n",
    "                    history['accuracy'].append(accuracy_train.item())\n",
    "            print()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cnn.eval().cuda()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# for images, labels in test_loader:\n",
    "#     images = Variable(images)\n",
    "#     labels= labels.squeeze(1)\n",
    "#     outputs = cnn(images)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     total += labels.size(0)\n",
    "#     correct += (predicted.float() == labels).sum()\n",
    "# print('Test Accuracy of the model on the 60000 test images: %.4f %%' % (100*correct.item() / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def predict_test_set(model, loader, filenames):\n",
    "    predictions = []\n",
    "    for images in loader:\n",
    "        images = Variable(images).cuda()\n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        predictions.extend(prediction.cpu().numpy())\n",
    "    results_df = pd.DataFrame({'image': test_filenames, 'class': predictions}, columns=['image', 'class'])\n",
    "    results_df.to_csv('results.csv',sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_loader, test_loader = create_datasets_dataloaders(train_images, train_labels)\n",
    "# cnn = ResNetMine(Bottleneck, [1, 1, 1, 1]).cuda()\n",
    "# trained_model = train(cnn, train_loader, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##predict on testset\n",
    "\n",
    "# test_transforms = transforms. Compose([\n",
    "#         transforms.CenterCrop(64),\n",
    "#         transforms.ToTensor()\n",
    "#     ])\n",
    "\n",
    "# test_dataset = ListsTestDataset(test_images, transform = test_transforms)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = False)\n",
    "\n",
    "# predict_test_set(trained_model, test_loader, test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, test_loader, num_epochs):\n",
    "    learning_rate = 0.0001\n",
    "    weight_decay = 0.00005\n",
    "    batch_size = train_loader.batch_size\n",
    "    criterion = nn.CrossEntropyLoss();\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay = weight_decay);\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate);\n",
    "    #Training\n",
    "    history = {'batch': [], 'loss': [], 'accuracy': []}\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train().cuda()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = Variable(images).cuda()\n",
    "            labels = Variable(labels).squeeze(1).long().cuda()#.cpu()\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, argmax = torch.max(outputs, 1)\n",
    "            accuracy_train = (labels == argmax.squeeze()).float().mean()*100\n",
    "            # Show progress\n",
    "            if (i+1) % 32 == 0:\n",
    "                log = \" \".join([\n",
    "                  \"Epoch : %d/%d\" % (epoch+1, num_epochs),\n",
    "                  \"Iter : %d/%d\" % (i+1, len(train_loader.dataset)//batch_size),\n",
    "                  \"Loss: %.4f\" % loss.item(),\n",
    "                  \"Accuracy: %.4f\" % accuracy_train])\n",
    "                print('\\r{}'.format(log), end='')\n",
    "                history['batch'].append(i)\n",
    "                history['loss'].append(loss.item())\n",
    "                history['accuracy'].append(accuracy_train.item())\n",
    "        print()\n",
    "        ##VALIDATION SCORE AFTER EVERY EPOCH\n",
    "        model.eval().cuda()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = Variable(images).cuda()\n",
    "            labels= labels.squeeze(1)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.cpu().long() == labels).sum()\n",
    "        print('VALIDATION SET ACCURACY: %.4f %%' % (100*correct.item() / total))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import NNs\n",
    "import math\n",
    "importlib.reload(NNs)\n",
    "from NNs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 34, 34]             576\n",
      "       BatchNorm2d-2           [-1, 64, 34, 34]             128\n",
      "              ReLU-3           [-1, 64, 34, 34]               0\n",
      "         MaxPool2d-4           [-1, 64, 17, 17]               0\n",
      "            Conv2d-5           [-1, 64, 17, 17]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 17, 17]             128\n",
      "              ReLU-7           [-1, 64, 17, 17]               0\n",
      "            Conv2d-8           [-1, 64, 17, 17]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 17, 17]             128\n",
      "             ReLU-10           [-1, 64, 17, 17]               0\n",
      "           Conv2d-11          [-1, 256, 17, 17]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 17, 17]             512\n",
      "           Conv2d-13          [-1, 256, 17, 17]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 17, 17]             512\n",
      "             ReLU-15          [-1, 256, 17, 17]               0\n",
      "       Bottleneck-16          [-1, 256, 17, 17]               0\n",
      "           Conv2d-17          [-1, 128, 17, 17]          32,768\n",
      "      BatchNorm2d-18          [-1, 128, 17, 17]             256\n",
      "             ReLU-19          [-1, 128, 17, 17]               0\n",
      "           Conv2d-20            [-1, 128, 9, 9]         147,456\n",
      "      BatchNorm2d-21            [-1, 128, 9, 9]             256\n",
      "             ReLU-22            [-1, 128, 9, 9]               0\n",
      "           Conv2d-23            [-1, 512, 9, 9]          65,536\n",
      "      BatchNorm2d-24            [-1, 512, 9, 9]           1,024\n",
      "           Conv2d-25            [-1, 512, 9, 9]         131,072\n",
      "      BatchNorm2d-26            [-1, 512, 9, 9]           1,024\n",
      "             ReLU-27            [-1, 512, 9, 9]               0\n",
      "       Bottleneck-28            [-1, 512, 9, 9]               0\n",
      "        AvgPool2d-29            [-1, 512, 4, 4]               0\n",
      "           Linear-30                  [-1, 121]         991,353\n",
      "================================================================\n",
      "Total params: 1,446,457\n",
      "Trainable params: 1,446,457\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 9.11\n",
      "Params size (MB): 5.52\n",
      "Estimated Total Size (MB): 14.65\n",
      "----------------------------------------------------------------\n",
      "Epoch : 1/150 Iter : 672/680 Loss: 2.7497 Accuracy: 31.2500\n",
      "VALIDATION SET ACCURACY: 31.3507 %\n",
      "Epoch : 2/150 Iter : 672/680 Loss: 2.3251 Accuracy: 34.3750\n",
      "VALIDATION SET ACCURACY: 38.4552 %\n",
      "Epoch : 3/150 Iter : 672/680 Loss: 2.6095 Accuracy: 31.2500\n",
      "VALIDATION SET ACCURACY: 40.5618 %\n",
      "Epoch : 4/150 Iter : 672/680 Loss: 2.2112 Accuracy: 43.7500\n",
      "VALIDATION SET ACCURACY: 43.4118 %\n",
      "Epoch : 5/150 Iter : 672/680 Loss: 2.5163 Accuracy: 28.1250\n",
      "VALIDATION SET ACCURACY: 45.3532 %\n",
      "Epoch : 6/150 Iter : 672/680 Loss: 1.7920 Accuracy: 53.1250\n",
      "VALIDATION SET ACCURACY: 45.7662 %\n",
      "Epoch : 7/150 Iter : 672/680 Loss: 1.2864 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 52.1685 %\n",
      "Epoch : 8/150 Iter : 672/680 Loss: 2.2504 Accuracy: 28.1250\n",
      "VALIDATION SET ACCURACY: 51.2598 %\n",
      "Epoch : 9/150 Iter : 672/680 Loss: 1.3366 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 53.2838 %\n",
      "Epoch : 10/150 Iter : 672/680 Loss: 1.8869 Accuracy: 43.7500\n",
      "VALIDATION SET ACCURACY: 52.7468 %\n",
      "Epoch : 11/150 Iter : 672/680 Loss: 1.9713 Accuracy: 28.1250\n",
      "VALIDATION SET ACCURACY: 54.6055 %\n",
      "Epoch : 12/150 Iter : 672/680 Loss: 1.7532 Accuracy: 46.8750\n",
      "VALIDATION SET ACCURACY: 54.2751 %\n",
      "Epoch : 13/150 Iter : 672/680 Loss: 2.1341 Accuracy: 37.5000\n",
      "VALIDATION SET ACCURACY: 55.1012 %\n",
      "Epoch : 14/150 Iter : 672/680 Loss: 1.8995 Accuracy: 37.5000\n",
      "VALIDATION SET ACCURACY: 52.6642 %\n",
      "Epoch : 15/150 Iter : 672/680 Loss: 1.4198 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 56.9186 %\n",
      "Epoch : 16/150 Iter : 672/680 Loss: 1.7373 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 55.9273 %\n",
      "Epoch : 17/150 Iter : 672/680 Loss: 1.3042 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 50.4750 %\n",
      "Epoch : 18/150 Iter : 672/680 Loss: 1.7832 Accuracy: 40.6250\n",
      "VALIDATION SET ACCURACY: 55.1012 %\n",
      "Epoch : 19/150 Iter : 672/680 Loss: 1.2901 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 56.6295 %\n",
      "Epoch : 20/150 Iter : 672/680 Loss: 1.5213 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 58.0752 %\n",
      "Epoch : 21/150 Iter : 672/680 Loss: 1.6956 Accuracy: 40.6250\n",
      "VALIDATION SET ACCURACY: 57.2904 %\n",
      "Epoch : 22/150 Iter : 672/680 Loss: 1.9453 Accuracy: 50.0000\n",
      "VALIDATION SET ACCURACY: 48.2858 %\n",
      "Epoch : 23/150 Iter : 672/680 Loss: 1.3796 Accuracy: 43.7500\n",
      "VALIDATION SET ACCURACY: 60.0165 %\n",
      "Epoch : 24/150 Iter : 672/680 Loss: 1.8939 Accuracy: 53.1250\n",
      "VALIDATION SET ACCURACY: 60.8013 %\n",
      "Epoch : 25/150 Iter : 672/680 Loss: 1.6915 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 58.4056 %\n",
      "Epoch : 26/150 Iter : 672/680 Loss: 1.6989 Accuracy: 50.0000\n",
      "VALIDATION SET ACCURACY: 58.5295 %\n",
      "Epoch : 27/150 Iter : 672/680 Loss: 1.1361 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 56.9186 %\n",
      "Epoch : 28/150 Iter : 672/680 Loss: 1.3772 Accuracy: 50.0000\n",
      "VALIDATION SET ACCURACY: 61.4622 %\n",
      "Epoch : 29/150 Iter : 672/680 Loss: 1.0416 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 58.9426 %\n",
      "Epoch : 30/150 Iter : 672/680 Loss: 1.4771 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 59.8513 %\n",
      "Epoch : 31/150 Iter : 672/680 Loss: 1.7141 Accuracy: 53.1250\n",
      "VALIDATION SET ACCURACY: 61.1731 %\n",
      "Epoch : 32/150 Iter : 672/680 Loss: 1.3917 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 61.2970 %\n",
      "Epoch : 33/150 Iter : 672/680 Loss: 1.4883 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 62.5774 %\n",
      "Epoch : 34/150 Iter : 672/680 Loss: 0.8483 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 60.5948 %\n",
      "Epoch : 35/150 Iter : 672/680 Loss: 1.5626 Accuracy: 50.0000\n",
      "VALIDATION SET ACCURACY: 61.6274 %\n",
      "Epoch : 36/150 Iter : 672/680 Loss: 1.2226 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 58.4469 %\n",
      "Epoch : 37/150 Iter : 672/680 Loss: 1.2196 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 62.6601 %\n",
      "Epoch : 38/150 Iter : 672/680 Loss: 1.3095 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 63.1970 %\n",
      "Epoch : 39/150 Iter : 672/680 Loss: 1.8734 Accuracy: 53.1250\n",
      "VALIDATION SET ACCURACY: 62.2057 %\n",
      "Epoch : 40/150 Iter : 672/680 Loss: 1.8125 Accuracy: 50.0000\n",
      "VALIDATION SET ACCURACY: 62.1644 %\n",
      "Epoch : 41/150 Iter : 672/680 Loss: 1.0905 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 63.4449 %\n",
      "Epoch : 42/150 Iter : 672/680 Loss: 0.8483 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 62.6188 %\n",
      "Epoch : 43/150 Iter : 672/680 Loss: 1.0663 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 63.8579 %\n",
      "Epoch : 44/150 Iter : 672/680 Loss: 1.1996 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 63.2383 %\n",
      "Epoch : 45/150 Iter : 672/680 Loss: 1.2863 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 63.2383 %\n",
      "Epoch : 46/150 Iter : 672/680 Loss: 0.8907 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 61.7513 %\n",
      "Epoch : 47/150 Iter : 672/680 Loss: 1.3614 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 64.3536 %\n",
      "Epoch : 48/150 Iter : 672/680 Loss: 1.1086 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 63.3622 %\n",
      "Epoch : 49/150 Iter : 672/680 Loss: 1.1066 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 64.0644 %\n",
      "Epoch : 50/150 Iter : 672/680 Loss: 0.8247 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 64.8905 %\n",
      "Epoch : 51/150 Iter : 672/680 Loss: 1.0039 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 64.5188 %\n",
      "Epoch : 52/150 Iter : 672/680 Loss: 0.9078 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 63.1557 %\n",
      "Epoch : 53/150 Iter : 672/680 Loss: 1.1107 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 61.3796 %\n",
      "Epoch : 54/150 Iter : 672/680 Loss: 1.5199 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 63.4449 %\n",
      "Epoch : 55/150 Iter : 672/680 Loss: 1.1365 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 64.4362 %\n",
      "Epoch : 56/150 Iter : 672/680 Loss: 1.2454 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 63.2796 %\n",
      "Epoch : 57/150 Iter : 672/680 Loss: 0.9995 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 63.8992 %\n",
      "Epoch : 58/150 Iter : 672/680 Loss: 0.7956 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 64.8079 %\n",
      "Epoch : 59/150 Iter : 672/680 Loss: 1.2754 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 64.5188 %\n",
      "Epoch : 60/150 Iter : 672/680 Loss: 1.1764 Accuracy: 53.1250\n",
      "VALIDATION SET ACCURACY: 63.2796 %\n",
      "Epoch : 61/150 Iter : 672/680 Loss: 1.0043 Accuracy: 87.5000\n",
      "VALIDATION SET ACCURACY: 62.5361 %\n",
      "Epoch : 62/150 Iter : 672/680 Loss: 0.7368 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 64.8079 %\n",
      "Epoch : 63/150 Iter : 672/680 Loss: 1.0613 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 64.6840 %\n",
      "Epoch : 64/150 Iter : 672/680 Loss: 1.1155 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 64.4362 %\n",
      "Epoch : 65/150 Iter : 672/680 Loss: 1.3872 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 66.0471 %\n",
      "Epoch : 66/150 Iter : 672/680 Loss: 1.0587 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 66.2536 %\n",
      "Epoch : 67/150 Iter : 672/680 Loss: 1.0420 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 59.8100 %\n",
      "Epoch : 68/150 Iter : 672/680 Loss: 1.2049 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 64.7253 %\n",
      "Epoch : 69/150 Iter : 672/680 Loss: 1.2882 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 66.2949 %\n",
      "Epoch : 70/150 Iter : 672/680 Loss: 1.0086 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 63.3622 %\n",
      "Epoch : 71/150 Iter : 672/680 Loss: 1.3716 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 63.5688 %\n",
      "Epoch : 72/150 Iter : 672/680 Loss: 1.1170 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 64.1057 %\n",
      "Epoch : 73/150 Iter : 672/680 Loss: 0.8793 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 64.4775 %\n",
      "Epoch : 74/150 Iter : 672/680 Loss: 1.0668 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 66.4601 %\n",
      "Epoch : 75/150 Iter : 672/680 Loss: 1.0886 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 67.0797 %\n",
      "Epoch : 76/150 Iter : 672/680 Loss: 1.3976 Accuracy: 53.1250\n",
      "VALIDATION SET ACCURACY: 63.8579 %\n",
      "Epoch : 77/150 Iter : 672/680 Loss: 1.0747 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 61.4209 %\n",
      "Epoch : 78/150 Iter : 672/680 Loss: 1.0382 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 65.1384 %\n",
      "Epoch : 79/150 Iter : 672/680 Loss: 1.0758 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 61.6274 %\n",
      "Epoch : 80/150 Iter : 672/680 Loss: 0.7526 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 66.2949 %\n",
      "Epoch : 81/150 Iter : 672/680 Loss: 0.8671 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 65.5514 %\n",
      "Epoch : 82/150 Iter : 672/680 Loss: 1.4850 Accuracy: 43.7500\n",
      "VALIDATION SET ACCURACY: 66.5841 %\n",
      "Epoch : 83/150 Iter : 672/680 Loss: 0.8524 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 67.2036 %\n",
      "Epoch : 84/150 Iter : 672/680 Loss: 0.8922 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 57.4969 %\n",
      "Epoch : 85/150 Iter : 672/680 Loss: 0.6827 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 67.0797 %\n",
      "Epoch : 86/150 Iter : 672/680 Loss: 1.2829 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 66.2949 %\n",
      "Epoch : 87/150 Iter : 672/680 Loss: 0.9338 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 67.0797 %\n",
      "Epoch : 88/150 Iter : 672/680 Loss: 0.8331 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 64.3949 %\n",
      "Epoch : 89/150 Iter : 672/680 Loss: 0.8208 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 66.3362 %\n",
      "Epoch : 90/150 Iter : 672/680 Loss: 0.6972 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 64.5188 %\n",
      "Epoch : 91/150 Iter : 672/680 Loss: 0.9865 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 62.2883 %\n",
      "Epoch : 92/150 Iter : 672/680 Loss: 1.0416 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 54.3164 %\n",
      "Epoch : 93/150 Iter : 672/680 Loss: 0.5951 Accuracy: 84.3750\n",
      "VALIDATION SET ACCURACY: 60.0991 %\n",
      "Epoch : 94/150 Iter : 672/680 Loss: 1.0523 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 59.4796 %\n",
      "Epoch : 95/150 Iter : 672/680 Loss: 0.5401 Accuracy: 90.6250\n",
      "VALIDATION SET ACCURACY: 66.7906 %\n",
      "Epoch : 96/150 Iter : 672/680 Loss: 1.2056 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 67.1210 %\n",
      "Epoch : 97/150 Iter : 672/680 Loss: 0.7378 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 65.4688 %\n",
      "Epoch : 98/150 Iter : 672/680 Loss: 1.0041 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 68.0297 %\n",
      "Epoch : 99/150 Iter : 672/680 Loss: 0.8219 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 67.2449 %\n",
      "Epoch : 100/150 Iter : 672/680 Loss: 0.8773 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 62.9079 %\n",
      "Epoch : 101/150 Iter : 672/680 Loss: 0.7136 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 66.1297 %\n",
      "Epoch : 102/150 Iter : 672/680 Loss: 0.7405 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 68.1124 %\n",
      "Epoch : 103/150 Iter : 672/680 Loss: 0.7749 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 66.8732 %\n",
      "Epoch : 104/150 Iter : 672/680 Loss: 0.5661 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 65.2210 %\n",
      "Epoch : 105/150 Iter : 672/680 Loss: 0.9108 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 68.4428 %\n",
      "Epoch : 106/150 Iter : 672/680 Loss: 0.8600 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 64.8492 %\n",
      "Epoch : 107/150 Iter : 672/680 Loss: 0.5920 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 67.8232 %\n",
      "Epoch : 108/150 Iter : 672/680 Loss: 1.2031 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 68.8558 %\n",
      "Epoch : 109/150 Iter : 672/680 Loss: 0.6985 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 64.1884 %\n",
      "Epoch : 110/150 Iter : 672/680 Loss: 0.6634 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 67.7819 %\n",
      "Epoch : 111/150 Iter : 672/680 Loss: 0.8298 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 68.7319 %\n",
      "Epoch : 112/150 Iter : 672/680 Loss: 0.9756 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 67.1623 %\n",
      "Epoch : 113/150 Iter : 672/680 Loss: 1.2408 Accuracy: 53.1250\n",
      "VALIDATION SET ACCURACY: 68.6493 %\n",
      "Epoch : 114/150 Iter : 672/680 Loss: 0.6521 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 68.7732 %\n",
      "Epoch : 115/150 Iter : 672/680 Loss: 1.0408 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 52.5403 %\n",
      "Epoch : 116/150 Iter : 672/680 Loss: 0.6437 Accuracy: 84.3750\n",
      "VALIDATION SET ACCURACY: 54.7708 %\n",
      "Epoch : 117/150 Iter : 672/680 Loss: 1.0037 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 67.8232 %\n",
      "Epoch : 118/150 Iter : 672/680 Loss: 1.1727 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 68.2363 %\n",
      "Epoch : 119/150 Iter : 672/680 Loss: 0.8576 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 68.9798 %\n",
      "Epoch : 120/150 Iter : 672/680 Loss: 1.0871 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 66.9145 %\n",
      "Epoch : 121/150 Iter : 672/680 Loss: 0.8053 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 67.9471 %\n",
      "Epoch : 122/150 Iter : 672/680 Loss: 0.6214 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 66.8732 %\n",
      "Epoch : 123/150 Iter : 672/680 Loss: 0.9436 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 68.8145 %\n",
      "Epoch : 124/150 Iter : 672/680 Loss: 1.2264 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 63.7340 %\n",
      "Epoch : 125/150 Iter : 672/680 Loss: 0.6260 Accuracy: 84.3750\n",
      "VALIDATION SET ACCURACY: 67.8645 %\n",
      "Epoch : 126/150 Iter : 672/680 Loss: 0.8115 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 67.9471 %\n",
      "Epoch : 127/150 Iter : 672/680 Loss: 0.8418 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 66.2536 %\n",
      "Epoch : 128/150 Iter : 672/680 Loss: 1.4051 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 60.8426 %\n",
      "Epoch : 129/150 Iter : 672/680 Loss: 1.3776 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 62.8666 %\n",
      "Epoch : 130/150 Iter : 672/680 Loss: 0.7297 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 67.2036 %\n",
      "Epoch : 131/150 Iter : 672/680 Loss: 1.0016 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 61.9992 %\n",
      "Epoch : 132/150 Iter : 672/680 Loss: 0.9153 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 65.5514 %\n",
      "Epoch : 133/150 Iter : 672/680 Loss: 0.6999 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 61.6687 %\n",
      "Epoch : 134/150 Iter : 672/680 Loss: 1.0819 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 66.9558 %\n",
      "Epoch : 135/150 Iter : 672/680 Loss: 0.7417 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 67.1210 %\n",
      "Epoch : 136/150 Iter : 672/680 Loss: 1.0353 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 67.2862 %\n",
      "Epoch : 137/150 Iter : 672/680 Loss: 0.5963 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 68.1950 %\n",
      "Epoch : 138/150 Iter : 672/680 Loss: 0.7995 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 67.1210 %\n",
      "Epoch : 139/150 Iter : 672/680 Loss: 0.6545 Accuracy: 65.6250\n",
      "VALIDATION SET ACCURACY: 66.3775 %\n",
      "Epoch : 140/150 Iter : 672/680 Loss: 1.0370 Accuracy: 56.2500\n",
      "VALIDATION SET ACCURACY: 68.0710 %\n",
      "Epoch : 141/150 Iter : 672/680 Loss: 0.8236 Accuracy: 68.7500\n",
      "VALIDATION SET ACCURACY: 66.1297 %\n",
      "Epoch : 142/150 Iter : 672/680 Loss: 0.7987 Accuracy: 78.1250\n",
      "VALIDATION SET ACCURACY: 68.7319 %\n",
      "Epoch : 143/150 Iter : 672/680 Loss: 0.4914 Accuracy: 87.5000\n",
      "VALIDATION SET ACCURACY: 68.1537 %\n",
      "Epoch : 144/150 Iter : 672/680 Loss: 0.5240 Accuracy: 81.2500\n",
      "VALIDATION SET ACCURACY: 69.1037 %\n",
      "Epoch : 145/150 Iter : 672/680 Loss: 0.8297 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 68.7319 %\n",
      "Epoch : 146/150 Iter : 672/680 Loss: 0.3358 Accuracy: 87.5000\n",
      "VALIDATION SET ACCURACY: 68.9385 %\n",
      "Epoch : 147/150 Iter : 672/680 Loss: 0.7313 Accuracy: 71.8750\n",
      "VALIDATION SET ACCURACY: 68.2363 %\n",
      "Epoch : 148/150 Iter : 672/680 Loss: 0.8375 Accuracy: 75.0000\n",
      "VALIDATION SET ACCURACY: 64.7666 %\n",
      "Epoch : 149/150 Iter : 672/680 Loss: 0.8435 Accuracy: 59.3750\n",
      "VALIDATION SET ACCURACY: 63.8579 %\n",
      "Epoch : 150/150 Iter : 672/680 Loss: 0.9107 Accuracy: 62.5000\n",
      "VALIDATION SET ACCURACY: 67.9884 %\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 34, 34]             576\n",
      "       BatchNorm2d-2           [-1, 64, 34, 34]             128\n",
      "              ReLU-3           [-1, 64, 34, 34]               0\n",
      "         MaxPool2d-4           [-1, 64, 17, 17]               0\n",
      "            Conv2d-5           [-1, 64, 17, 17]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 17, 17]             128\n",
      "              ReLU-7           [-1, 64, 17, 17]               0\n",
      "            Conv2d-8           [-1, 64, 17, 17]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 17, 17]             128\n",
      "             ReLU-10           [-1, 64, 17, 17]               0\n",
      "           Conv2d-11          [-1, 256, 17, 17]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 17, 17]             512\n",
      "           Conv2d-13          [-1, 256, 17, 17]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 17, 17]             512\n",
      "             ReLU-15          [-1, 256, 17, 17]               0\n",
      "       Bottleneck-16          [-1, 256, 17, 17]               0\n",
      "           Conv2d-17          [-1, 128, 17, 17]          32,768\n",
      "      BatchNorm2d-18          [-1, 128, 17, 17]             256\n",
      "             ReLU-19          [-1, 128, 17, 17]               0\n",
      "           Conv2d-20            [-1, 128, 9, 9]         147,456\n",
      "      BatchNorm2d-21            [-1, 128, 9, 9]             256\n",
      "             ReLU-22            [-1, 128, 9, 9]               0\n",
      "           Conv2d-23            [-1, 512, 9, 9]          65,536\n",
      "      BatchNorm2d-24            [-1, 512, 9, 9]           1,024\n",
      "           Conv2d-25            [-1, 512, 9, 9]         131,072\n",
      "      BatchNorm2d-26            [-1, 512, 9, 9]           1,024\n",
      "             ReLU-27            [-1, 512, 9, 9]               0\n",
      "       Bottleneck-28            [-1, 512, 9, 9]               0\n",
      "        AvgPool2d-29            [-1, 512, 4, 4]               0\n",
      "           Linear-30                  [-1, 121]         991,353\n",
      "================================================================\n",
      "Total params: 1,446,457\n",
      "Trainable params: 1,446,457\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 9.11\n",
      "Params size (MB): 5.52\n",
      "Estimated Total Size (MB): 14.65\n",
      "----------------------------------------------------------------\n",
      "Epoch : 1/150 Iter : 352/680 Loss: 2.8405 Accuracy: 34.3750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f916a5f0bc8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#     print(summary(cnn, (1,28,28)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mtrained_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-06d5b37b9072>\u001b[0m in \u001b[0;36mtrain_and_validate\u001b[0;34m(model, train_loader, test_loader, num_epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0maccuracy_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_92/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=True)\n",
    "trained_models = []\n",
    "for train_indexes, validation_indexes in kf.split(train_images):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    \n",
    "    for i in train_indexes:\n",
    "        X_train.append(train_images[i])\n",
    "        y_train.append(train_labels[i])\n",
    "    for j in validation_indexes:\n",
    "        X_val.append(train_images[j])\n",
    "        y_val.append(train_labels[j])\n",
    "    train_loader, test_loader = create_datasets_dataloaders(\n",
    "        X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    #Training\n",
    "    cnn = ResNetMine(Bottleneck, [1,1]).cuda()\n",
    "#     cnn = CNN().cuda()\n",
    "    summary(cnn, (1,64,64))\n",
    "\n",
    "#     print(summary(cnn, (1,28,28)))\n",
    "    trained_model = train_and_validate(cnn, train_loader, test_loader, num_epochs=150)\n",
    "    trained_models.append(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = trained_models[0].eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on testset\n",
    "def predict_test_set(model, loader, filenames):\n",
    "    predictions = []\n",
    "    for images in loader:\n",
    "        images = Variable(images).cuda()\n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        predictions.extend(prediction.cpu().numpy())\n",
    "    results_df = pd.DataFrame({'image': test_filenames, 'class': predictions}, columns=['image', 'class'])\n",
    "    results_df.to_csv('results.csv',sep = ',', index = False)\n",
    "\n",
    "\n",
    "test_transforms = transforms. Compose([\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "test_dataset = ListsTestDataset(test_images, transform = test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = False)\n",
    "\n",
    "predict_test_set(final_model, test_loader, test_filenames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "torch_92"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
